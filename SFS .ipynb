{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the packages for the execution of the code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import itertools\n",
    "from pandas import DataFrame\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from sklearn import svm  \n",
    "import statistics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing csv and converting it into dataframe\n",
    "dataframe_balance= pd.read_csv(\"SPECT.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "['Partial Diagnosis 8', 'Partial Diagnosis 2']\n"
     ]
    }
   ],
   "source": [
    "col_list=list(dataframe_balance.columns)\n",
    "col_list.pop(0)\n",
    "#print(col_list)\n",
    "\n",
    "#Stratified K fold Validation, splitting the data on the basis of class first.\n",
    "df_pos=dataframe_balance[dataframe_balance[\"Overall_Diagnosis\"]==1]\n",
    "df_neg=dataframe_balance[dataframe_balance[\"Overall_Diagnosis\"]==0]\n",
    "\n",
    "#splitting both the classes into k folds.\n",
    "df_pos_splits=np.array_split(df_pos,5)\n",
    "df_neg_splits=np.array_split(df_neg,5)\n",
    "\n",
    "Feature_list=[]\n",
    "max_acc_before=0\n",
    "\n",
    "\n",
    "#Cross Validation starts here, iterating one of the dataframes and creating test set and training set for each fold.    \n",
    "for i in range(len(df_pos_splits)):\n",
    "    testing_pos=df_pos_splits[i]\n",
    "    testing_neg=df_neg_splits[i]\n",
    "    frames=[testing_pos, testing_neg]\n",
    "    testing_full=pd.concat(frames)\n",
    "\n",
    "\n",
    "    if i==0:\n",
    "        training_pos=df_pos_splits[i+1:]\n",
    "        training_pos_full=pd.concat(training_pos)\n",
    "        training_neg=df_neg_splits[i+1:]\n",
    "        training_neg_full=pd.concat(training_neg)\n",
    "        frames=[training_pos_full,training_neg_full]\n",
    "        training_full=pd.concat(frames)\n",
    "\n",
    "    else:\n",
    "        training_pos=df_pos_splits[0:i]+df_pos_splits[i+1:]\n",
    "        training_pos_full=pd.concat(training_pos)\n",
    "        training_neg=df_neg_splits[0:i]+df_neg_splits[i+1:]\n",
    "        training_neg_full=pd.concat(training_neg)\n",
    "        frames=[training_pos_full,training_neg_full]\n",
    "        training_full=pd.concat(frames)\n",
    "\n",
    "\n",
    "    #Storing the class label for the training set for the respective fold.\n",
    "    class_label_train=training_full['Overall_Diagnosis']\n",
    "    #print (class_label_train)\n",
    "\n",
    "    class_label_test=testing_full['Overall_Diagnosis']\n",
    "    a = (class_label_train.values)\n",
    "    \n",
    "    dic_feature_acc={}\n",
    "    #iTerating feature by feature and appending it to a listof features which is emppty in the beginning and it stores that\n",
    "    #feature which provides the maximum  average accuracy over k folds.\n",
    "    for col in col_list:\n",
    "\n",
    "        Feature_list.append(col)\n",
    "\n",
    "        #Applying svm over the training set to fit the model and then testing it on the tesing set, along with the test labels.\n",
    "        curr_feature=training_full[Feature_list]\n",
    "        curr_test_feature=testing_full[Feature_list]\n",
    "        clf = SVC(gamma='auto')\n",
    "        clf.fit(curr_feature,class_label_train)\n",
    "        avg_acc=clf.score(curr_test_feature,class_label_test)\n",
    "        # removing the col with which we just calculated the avg accuracy and move for calulating accuracy with the next feature.\n",
    "        Feature_list.remove(col)\n",
    "        if col not in dic_feature_acc.keys():\n",
    "            dic_feature_acc[col]=[avg_acc]\n",
    "        else:\n",
    "\n",
    "            dic_feature_acc[col].append(avg_acc)\n",
    "\n",
    "    dic_avgfold_acc={}    \n",
    "    max_acc=0\n",
    "    feature=\"\"\n",
    "    \n",
    "    #calculating the average of the k folds accuracy calculated ffor a particular feature. if it is greater than some other features accuracy\n",
    "    #it is selected as the feature and added to the subset.\n",
    "    for key,value in dic_feature_acc.items():\n",
    "        avg=statistics.mean(value)\n",
    "        #print(avg)\n",
    "        \n",
    "        if avg>max_acc:\n",
    "            max_acc=avg\n",
    "            feature=key\n",
    "    \n",
    "    #If the accuracy decreases on adding a feature we stop.\n",
    "    if max_acc>max_acc_before:\n",
    "        Feature_list.append(feature)\n",
    "        col_list.remove(feature)\n",
    "        max_acc_before=max_acc\n",
    "        \n",
    "    else:\n",
    "        print(\"True\")\n",
    "        break\n",
    "    \n",
    "print(Feature_list)\n",
    "\n",
    "        \n",
    "        \n",
    "   \n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
